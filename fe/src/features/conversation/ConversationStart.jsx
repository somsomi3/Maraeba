import { useState, useEffect, useRef } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';
import './ConversationStart.css';
import catAvatar from '../../assets/images/aiCat.png';
import smileAvatar from '../../assets/images/smile.png';
import { springApi, flaskApi } from '../../utils/api';
import recordbtn from '../../assets/icons/record.png';
import pausebtn from '../../assets/icons/pause.png';
import ConversationStopPopup from '../../components/popup/ConversationStopPopup';

const ConversationStart = () => {
  const location = useLocation();
  const { sessionId, aiAnswer, aiRole, userRole } = location.state || {}; // AI ì²« ë©”ì‹œì§€ & ì—­í•  ë°›ìŒ
  const [messages, setMessages] = useState([{ role: 'ai', text: aiAnswer }]); // AI ì²« ë©”ì‹œì§€
  const [isRecording, setIsRecording] = useState(false); // ë…¹ìŒ ìƒíƒœ
  const [recordingIcon, setRecordingIcon] = useState(recordbtn); // ğŸ”¥ ë²„íŠ¼ ì•„ì´ì½˜ ìƒíƒœ ì¶”ê°€
  const [audioBlob, setAudioBlob] = useState(null); // ë…¹ìŒëœ ìŒì„± íŒŒì¼
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  // ğŸ”¥ ë…¹ìŒ ì‹œì‘
  const toggleRecording = async () => {
    if (!isRecording) {
      // âœ… ë…¹ìŒ ì‹œì‘
      setIsRecording(true);
      setRecordingIcon(pausebtn); // ğŸ¤ ë…¹ìŒ ì¤‘ ë²„íŠ¼ ë³€ê²½

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioFile = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        console.log("ğŸ¤ ë…¹ìŒëœ íŒŒì¼:", audioFile);
        setAudioBlob(audioFile);
        setRecordingIcon(recordbtn); // ğŸ” ë²„íŠ¼ ì›ë˜ëŒ€ë¡œ
        setIsRecording(false);
      };

      mediaRecorder.start();
    } else {
      // âœ… ë…¹ìŒ ì¤‘ì§€
      mediaRecorderRef.current?.stop();
      setIsRecording(false);
    }
  };

  // ğŸ”¥ ë…¹ìŒ ì™„ë£Œ í›„ STT ë³€í™˜ + AI ì‘ë‹µ
  const processAudio = async () => {
    if (!audioBlob) return;
  
    try {
      console.log("ğŸ¤ Sending audio to STT & AI...");
  
      // âœ… ìœ ì € ë§í’ì„ ì— ë…¹ìŒ ì¤‘ í…ìŠ¤íŠ¸ ì¶”ê°€ (STT ë³€í™˜ ì „)
      
      setMessages((prev) => [
        ...prev,
        { role: 'user', text: "..." }, // ìœ ì € ë§í’ì„  (STT ë³€í™˜ ì „)
        { role: 'ai', text: "..." } // AI ì‘ë‹µ ëŒ€ê¸°
      ]);
      
      const audioFile = new File([audioBlob], "recording.wav", { type: 'audio/wav' });
      const sttFormData = new FormData();
      sttFormData.append('file', audioFile);
  
      const sttResponse = await flaskApi.post('/ai/stt', sttFormData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });
  
      const userText = sttResponse.data.recognized_text || 'ğŸ¤ (ìŒì„± ë³€í™˜ ì‹¤íŒ¨)';
  
      // âœ… 2. AI ì‘ë‹µ ìš”ì²­
      if (!sessionId) {
        console.error("âŒ sessionIdê°€ ì—†ìŠµë‹ˆë‹¤!");
        return;
      }
  
      const chatFormData = new FormData();
      chatFormData.append('audio', audioBlob);
      chatFormData.append('sessionId', sessionId);
  
      const aiResponse = await springApi.post('/chat/play', chatFormData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });
  
      console.log("ğŸ¤– AI Response:", aiResponse.data.answer);
  
      // âœ… 3. UI ì—…ë°ì´íŠ¸ (STT ë³€í™˜ëœ ìœ ì € í…ìŠ¤íŠ¸ & AI ì‘ë‹µ ì¶”ê°€)
      setMessages((prev) => {
        const updatedMessages = [...prev];
        updatedMessages[updatedMessages.length - 2] = { role: 'user', text: userText }; // STT ë³€í™˜ëœ ìœ ì € ë§í’ì„  ì—…ë°ì´íŠ¸
        updatedMessages[updatedMessages.length - 1] = { role: 'ai', text: aiResponse.data.answer }; // AI ì‘ë‹µ ì—…ë°ì´íŠ¸
        return updatedMessages;
      });
  
      setAudioBlob(null);
    } catch (error) {
      console.error('ğŸš¨ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜:', error.response?.data || error.message);
    }
  };
  

  useEffect(() => {
    if (audioBlob) {
      processAudio();
    }
  }, [audioBlob]); // ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ì‹¤í–‰

  return (
    <div className="conversation-start-container">
      {/* AI ì—­í• ê³¼ ë©”ì‹œì§€ */}
      <div className="message-row ai">
        <img src={catAvatar} alt="AI ì•„ë°”íƒ€" className="avatar" />
        <div className="message-content">
          <p className="role-name">{aiRole || "ìƒëŒ€ì˜ ì—­í•  ì´ë¦„"}</p> {/* AI ì—­í•  í‘œì‹œ */}
          <div className="message-bubble">
            <p className="message-text">{messages[messages.length - 1].text}</p>
          </div>
        </div>
      </div>

      {/* ì‚¬ìš©ì ë©”ì‹œì§€ */}
      <div className="message-row user">
        <div className="message-content user-content">
          <p className="role-name">{userRole || "ë‚´ ì—­í• " }</p> 
          <div className="message-bubble">
            <p className="message-text">
              {messages.findLast(msg => msg.role === 'user')?.text || ''}
            </p>
          </div>
        </div>
        <img src={smileAvatar} alt="ìœ ì € ì•„ë°”íƒ€" className="avatar" />
      </div>

      {/* ğŸ”¥ ë…¹ìŒ ë²„íŠ¼ (ì´ë¯¸ì§€ í´ë¦­) */}
      <div className="footer">
        <img 
          src={recordingIcon} 
          alt="ë…¹ìŒ ë²„íŠ¼" 
          className={`record-button ${isRecording ? 'recording' : ''}`} 
          onClick={toggleRecording} 
        />
      </div>
      
      <ConversationStopPopup />
    </div>
  );
};

export default ConversationStart;
