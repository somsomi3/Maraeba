import { useState, useEffect } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';
import './ConversationStart.css';
import catAvatar from '../../assets/images/aiCat.png';
import smileAvatar from '../../assets/images/smile.png';
import { springApi, flaskApi } from '../../utils/api';
import recordbtn from '../../assets/icons/record.png';
import PausePopup from '../../components/popup/PausePopup';

const ConversationStart = () => {
  const location = useLocation();
  const { sessionId, aiAnswer, aiRole, userRole } = location.state || {}; // AI ì²« ë©”ì‹œì§€ & ì—­í•  ë°›ìŒ
  const [messages, setMessages] = useState([{ role: 'ai', text: aiAnswer }]); // AI ì²« ë©”ì‹œì§€
  const [isRecording, setIsRecording] = useState(false); // ë…¹ìŒ ìƒíƒœ
  const [audioBlob, setAudioBlob] = useState(null); // ë…¹ìŒëœ ìŒì„± íŒŒì¼
  const navigate = useNavigate();

  // ğŸ”¥ ë…¹ìŒ ì‹œì‘
  const startRecording = () => {
    if (isRecording) return; // ì¤‘ë³µ ë°©ì§€
    setIsRecording(true);
    setAudioBlob(null);

    navigator.mediaDevices.getUserMedia({ audio: true })
      .then((stream) => {
        const mediaRecorder = new MediaRecorder(stream);
        const audioChunks = [];

        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };

        mediaRecorder.onstop = () => {
          const audioFile = new Blob(audioChunks, { type: 'audio/webm' });
          console.log("ë…¹ìŒëœ íŒŒì¼", audioFile)
          setAudioBlob(audioFile);
          setIsRecording(false);
        };

        mediaRecorder.start();

        setTimeout(() => {
          mediaRecorder.stop();
        }, 5000); // 5ì´ˆ í›„ ìë™ ì¢…ë£Œ
      })
      .catch((error) => console.error('ğŸš¨ ë§ˆì´í¬ ê¶Œí•œ ì˜¤ë¥˜:', error));
  };

  // ğŸ”¥ ë…¹ìŒ ì™„ë£Œ í›„ STT ë³€í™˜ + AI ì‘ë‹µ
  const processAudio = async () => {
    if (!audioBlob) return;
  
    try {
      console.log("ğŸ¤ Sending audio to STT & AI...");
  
      // âœ… ìœ ì € ë§í’ì„ ì— ë…¹ìŒ ì¤‘ í…ìŠ¤íŠ¸ ì¶”ê°€ (STT ë³€í™˜ ì „)
      setMessages((prev) => [
        ...prev,
        { role: 'user', text: "..." }, // ìœ ì € ë§í’ì„  (STT ë³€í™˜ ì „)
        { role: 'ai', text: "ğŸ¤– AIê°€ ìƒê° ì¤‘..." } // AI ì‘ë‹µ ëŒ€ê¸°
      ]);
      
      const audioFile = new File([audioBlob], "recording.wav", { type: 'audio/wav' });
      const sttFormData = new FormData();
      sttFormData.append('file', audioFile);
  
      const sttResponse = await flaskApi.post('/ai/stt', sttFormData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });
  
      const userText = sttResponse.data.recognized_text || 'ğŸ¤ (ìŒì„± ë³€í™˜ ì‹¤íŒ¨)';
  
      // âœ… 2. AI ì‘ë‹µ ìš”ì²­
      if (!sessionId) {
        console.error("âŒ sessionIdê°€ ì—†ìŠµë‹ˆë‹¤!");
        return;
      }
  
      const chatFormData = new FormData();
      chatFormData.append('audio', audioBlob);
      chatFormData.append('sessionId', sessionId);
  
      const aiResponse = await springApi.post('/chat/play', chatFormData, {
        headers: { 'Content-Type': 'multipart/form-data' }
      });
  
      console.log("ğŸ¤– AI Response:", aiResponse.data.answer);
  
      // âœ… 3. UI ì—…ë°ì´íŠ¸ (STT ë³€í™˜ëœ ìœ ì € í…ìŠ¤íŠ¸ & AI ì‘ë‹µ ì¶”ê°€)
      setMessages((prev) => {
        const updatedMessages = [...prev];
        updatedMessages[updatedMessages.length - 2] = { role: 'user', text: userText }; // STT ë³€í™˜ëœ ìœ ì € ë§í’ì„  ì—…ë°ì´íŠ¸
        updatedMessages[updatedMessages.length - 1] = { role: 'ai', text: aiResponse.data.answer }; // AI ì‘ë‹µ ì—…ë°ì´íŠ¸
        return updatedMessages;
      });
  
      setAudioBlob(null);
    } catch (error) {
      console.error('ğŸš¨ ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜:', error.response?.data || error.message);
    }
  };
  

  useEffect(() => {
    if (audioBlob) {
      processAudio();
    }
  }, [audioBlob]); // ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ì‹¤í–‰

  return (
    <div className="conversation-start-container">
      {/* AI ì—­í• ê³¼ ë©”ì‹œì§€ */}
      <div className="message-row ai">
        <img src={catAvatar} alt="AI ì•„ë°”íƒ€" className="avatar" />
        <div className="message-content">
          <p className="role-name">{aiRole || "ìƒëŒ€ì˜ ì—­í•  ì´ë¦„"}</p> {/* AI ì—­í•  í‘œì‹œ */}
          <div className="message-bubble">
            <p className="message-text">{messages[messages.length - 1].text}</p>
          </div>
        </div>
      </div>

      {/* ì‚¬ìš©ì ë©”ì‹œì§€ */}
      <div className="message-row user">
        <div className="message-content user-content">
          <p className="role-name">{userRole || "ë‚´ ì—­í• " }</p> 
          <div className="message-bubble">
            <p className="message-text">
              {messages.findLast(msg => msg.role === 'user')?.text || ''}
            </p>
          </div>
        </div>
        <img src={smileAvatar} alt="ìœ ì € ì•„ë°”íƒ€" className="avatar" />
      </div>

      {/* ğŸ”¥ ë…¹ìŒ ë²„íŠ¼ (ì´ë¯¸ì§€ í´ë¦­) */}
      <div className="footer">
        <img 
          src={recordbtn} 
          alt="ë…¹ìŒ ë²„íŠ¼" 
          className={`record-button ${isRecording ? 'recording' : ''}`} 
          onClick={startRecording} 
        />
      </div>
      <PausePopup onExit={() => navigate("/prons")} title="ëŒ€í™”ë¥¼ ëë‚¼ê¹Œìš”?" />
    </div>
  );
};

export default ConversationStart;
